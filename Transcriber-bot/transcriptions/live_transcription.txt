 The previous lecture. Now let me technically define Hadoop. Hadoop is a distributed data processing platform that offers three core capabilities. The yarn stands for yet another resource manager. The name for the yarn doesn't correlate with Hadoop. However, yarn is the Hadoop cluster resource manager. We also call it Hadoop cluster operating system, but the Hadoop creators prefer to name it as a cluster resource manager. But what does it exactly do? Let's try to understand.
 And operating system allows multiple programs to be in memory and run simultaneously. And this is achieved by sharing resources such as CPU, memory and disk IO. The yarn does the same. It allows multiple applications to be associated with the resources.
 Now let's assume we have 5 computers shown here. We want to make a Hadoop cluster using these 5 computers. So we will install Hadoop on these computers and configure them to make a Hadoop cluster.
 Now, configuring a Hadoop cluster is as simple as installing software on your computer. I'll give you a demo in some other lecture. But for now, you can consider it automated work that you can do using a few clicks and following an installation result. Makes sense? Great. So, as soon we installed Hadoop and now these five computers form a Hadoop cluster. Hadoop uses a master flavor architecture. So one of these machines will become the master and the remaining will act as a worker load. And Hadoop will also install a Young Resource Manager Service on the...
 master. It also installs a node manager service on all the worker nodes. So this diagram represents the yarn configuration on a hadoop cluster. We have a 5 node cluster, one node acts as a master and runs the yarn resource manager service. The other 4 nodes act as a worker and run a node manager service. The node manager will regularly send the node status report to the resource manager. Now you want to run a data processing application on this cluster. That's why we created hadoop cluster, right? We created hadoop
