 you you
 you you This manager will request one of the node managers to start a resource container and run an application master in the container. And that is all. Your application starts running inside the application master container. But what is the container? It is a set of resources that includes memory and CPU.
  you you
 This manager will request one of the node managers to start a resource container and run an application master in the container. And that is all. Your application starts running inside the application master container. But what is the container? It is a set of resources that includes memory and CPU.
 For example, a yarn container may be a set of two CPU cores and four GB of memory. So whenever we refer to yarn container, you should think of a box of some CPU and memory. Make sense? Great. So we learned about the three components of Hadoob yarn. Yarn has three main components. Resource Manager, Node Manager and Application Master.
 things. I will start with an introduction to Hadoop and take you deep into Hadoop architecture. Then I will talk about some history and the origin of Hadoop. Hadoop became very popular, but we had many challenges with Hadoop. So I will talk about some challenges with the Hadoop platform. Finally, I will introduce you to Apache Spark and see how Spark overcomes those challenges. The last thing
 in this lecture will give you an idea of where Hadoob stands in today's technology space and how Spark has evolved beyond the Hadoob platform. The entire lecture will flow like a story. So do not skip anything and stick to the flow. Exxence? Great. Let's start with the following question. What is Hadoob? You already learned some overview of Hadoob in the previous lecture.
 Now let me technically define Hadoop. Hadoop is a distributed data processing platform that offers three core capabilities. The yarn stands for yet another resource manager. The name for the yarn doesn't correlate with Hadoop. However, yarn is the Hadoop cluster resource manager. You also call it Hadoop cluster operating system. But the Hadoop creators...
 preferred to name it as a cluster resource manager. But what does it exactly do? Let's try to understand it. An operating system allows multiple programs to be in memory and run simultaneously. And this is achieved by sharing resources such as CPU, memory and disk I.O. The yarn does the same. It allows multiple applications to run on
